{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentes de IA con Hugging Face\n",
    "Este cuaderno muestra cómo crear y usar agentes de IA utilizando los modelos de Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Instalar las dependencias necesarias\n",
    "!pip install transformers torch\n",
    "!pip install git+https://github.com/huggingface/notebooks.git\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importar las librerías necesarias\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1: Agente de Chat\n",
    "Vamos a crear un agente de chat simple usando un modelo de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cargar el modelo y el tokenizer\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def chat_with_agent():\n",
    "    print(\"Bienvenido al agente de chat!\")\n",
    "    print(\"Escribe 'salir' para terminar la conversación.\")\n",
    "    \n",
    "    chat_history = []\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\nTú: \")\n",
    "        if user_input.lower() == 'salir':\n",
    "            break\n",
    "        \n",
    "        # Agregar el input del usuario al historial\n",
    "        chat_history.append(f'\"{user_input}\"')\n",
    "        \n",
    "        # Preparar el input para el modelo\n",
    "        chat_input = \"\\n\".join(chat_history)\n",
    "        inputs = tokenizer(chat_input, return_tensors='pt')\n",
    "        \n",
    "        # Generar respuesta\n",
    "        response = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_length=1000,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        # Decodificar la respuesta\n",
    "        response_text = tokenizer.decode(response[:, inputs['input_ids'].shape[-1]:][0], skip_special_tokens=True)\n",
    "        \n",
    "        # Mostrar la respuesta\n",
    "        print(f'\nAgente: {response_text}')\n",
    "        \n",
    "        # Agregar la respuesta al historial\n",
    "        chat_history.append(f'Agente: {response_text}')\n",
    "\n",
    "# Iniciar el chat\n",
    "chat_with_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Agente de Tareas\n",
    "Vamos a crear un agente que puede realizar tareas específicas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class TaskAgent:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    def generate_response(self, task_description):\n",
    "        # Formatear la descripción de la tarea\n",
    "        prompt = f'\"\"\"\n",
    "        Tarea: {task_description}\n",
    "        \n",
    "        Genera una respuesta detallada y precisa para esta tarea.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generar respuesta\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt')\n",
    "        response = self.model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_length=500,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        return self.tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "# Crear y usar el agente\n",
    "agent = TaskAgent(\"gpt2-medium\")\n",
    "\n",
    "# Ejemplo de tarea\n",
    "task = \"\"\"\n",
    "Analiza el impacto de la IA en la sociedad.\n",
    "Incluye puntos positivos y negativos.\n",
    "\"\"\"\n",
    "\n",
    "response = agent.generate_response(task)\n",
    "print(\"\nRespuesta del agente:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Adicionales\n",
    "1. Implementa un agente que pueda interactuar con una base de datos\n",
    "2. Crea un agente que pueda generar código automáticamente\n",
    "3. Implementa un sistema de seguimiento de tareas\n",
    "4. Crea un agente que pueda analizar y resumir documentos\n",
    "5. Implementa un sistema de recomendación basado en IA"
   ]
  }
 ]
}
