{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Imágenes con Transformers de Hugging Face\n",
    "Este cuaderno muestra cómo usar diferentes modelos de transformers para analizar y procesar imágenes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Instalar las dependencias necesarias\n",
    "!pip install transformers torch torchvision\n",
    "!pip install git+https://github.com/huggingface/notebooks.git"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importar las librerías necesarias\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Función para cargar y mostrar una imagen\n",
    "def load_and_show_image(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    display(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ejemplo 1: Clasificación de imágenes con ViT (Vision Transformer)\n",
    "# Cargar el modelo y el preprocesador\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Probar con una imagen\n",
    "url = "https://images.unsplash.com/photo-1472214103451-9374bd1c798e?w=600"\n",
    "img = load_and_show_image(url)\n",
    "\n",
    "# Preprocesar la imagen\n",
    "inputs = processor(img, return_tensors="pt")\n",
    "\n",
    "# Obtener la clasificación\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    predicted_label = model.config.id2label[predicted_class_idx]\n",
    "\n",
    "print(f'\nLa imagen se clasifica como: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Detección de objetos con DETR\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")\n",
    "model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")\n",
    "\n",
    "# Usar la misma imagen\n",
    "inputs = processor(images=img, return_tensors="pt")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Convertir las salidas en detecciones\n",
    "target_sizes = torch.tensor([img.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "print("\nObjetos detectados:")\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(f'\"{model.config.id2label[label.item()]}\"', end=' ')\n",
    "    print(f'with {round(score.item(), 3)} confidence at location {box}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Adicionales\n",
    "1. Experimenta con diferentes modelos de transformers para imágenes\n",
    "2. Implementa un sistema de clasificación personalizado\n",
    "3. Agrega visualización de las cajas de detección\n",
    "4. Compara los resultados de diferentes modelos\n",
    "5. Implementa un sistema de búsqueda por similitud visual"
   ]
  }
 ]
}
